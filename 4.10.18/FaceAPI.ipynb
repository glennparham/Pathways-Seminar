{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Microsoft Cognitive Services: Facial Recognition\n",
    "This walkthrough shows you how to use the cognitive services [Face API](https://azure.microsoft.com/services/cognitive-services/face/) to detect faces in an image. \n",
    "\n",
    "## Prerequisites\n",
    "You must have a [Cognitive Services API account](https://docs.microsoft.com/azure/cognitive-services/cognitive-services-apis-create-account) with **Face API**. The [free trial](https://azure.microsoft.com/try/cognitive-services/?api=face-api) is sufficient for this quickstart. You need the subscription key provided when you activate your free trial, or you may use a paid subscription key from your Azure dashboard.\n",
    "\n",
    "## Running the walkthrough\n",
    "To continue with this walkthrough, replace `subscription_key` with a valid subscription key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = \"9b96f57788fe40ffbda6eba5523b4dc5\"\n",
    "assert subscription_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HERE IS YOUR ENDPOINT:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_api_url = 'https://westcentralus.api.cognitive.microsoft.com/face/v1.0/detect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Here is the location of the PHOTO that you'll be looking for faces in.**  It should be a link (i.e. 'https://www.~~.com')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "image_url = 'https://images.medicaldaily.com/sites/medicaldaily.com/files/styles/full_breakpoints_theme_medicaldaily_desktop_1x/public/2015/07/09/squirrel.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JUST RUN THIS CELL**. It will automatically send the photo to Microsoft to find the faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import HTML\n",
    "\n",
    "headers = { 'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "    \n",
    "params = {\n",
    "    'returnFaceId': 'true',\n",
    "    'returnFaceLandmarks': 'false',\n",
    "    'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise',\n",
    "}\n",
    "\n",
    "response = requests.post(face_api_url, params=params, headers=headers, json={\"url\": image_url})\n",
    "faces = response.json()\n",
    "HTML(\"<font size=5>Detected <font color='blue'>%d</font> faces in the image</font>\"%len(faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**RUN THIS CELL TO SEE WHAT MICROSOFT FOUND IN YOUR PHOTO.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import patches\n",
    "from io import BytesIO\n",
    "\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.imshow(image, alpha=0.6)\n",
    "for face in faces:\n",
    "    fr = face[\"faceRectangle\"]\n",
    "    fa = face[\"faceAttributes\"]\n",
    "    origin = (fr[\"left\"], fr[\"top\"])\n",
    "    p = patches.Rectangle(origin, fr[\"width\"], fr[\"height\"], fill=False, linewidth=2, color='b')\n",
    "    ax.axes.add_patch(p)\n",
    "    plt.text(origin[0], origin[1], \"%s, %d\"%(fa[\"gender\"].capitalize(), fa[\"age\"]), fontsize=20, weight=\"bold\", va=\"bottom\")\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**We can automate everything we did to just one function: annotate_image.** You just pass in an image path or url!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def annotate_image(image_url):\n",
    "    response = requests.post(face_api_url, params=params, headers=headers, json={\"url\": image_url})\n",
    "    faces = response.json()\n",
    "\n",
    "    image_file = BytesIO(requests.get(image_url).content)\n",
    "    image = Image.open(image_file)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = plt.imshow(image, alpha=0.6)\n",
    "    for face in faces:\n",
    "        fr = face[\"faceRectangle\"]\n",
    "        fa = face[\"faceAttributes\"]\n",
    "        origin = (fr[\"left\"], fr[\"top\"])\n",
    "        p = patches.Rectangle(origin, fr[\"width\"], \\\n",
    "                              fr[\"height\"], fill=False, linewidth=2, color='b')\n",
    "        ax.axes.add_patch(p)\n",
    "        plt.text(origin[0], origin[1], \"%s, %d\"%(fa[\"gender\"].capitalize(), fa[\"age\"]), \\\n",
    "                 fontsize=20, weight=\"bold\", va=\"bottom\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then call ``annotate_image`` on other images. A few examples samples are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "annotate_image(\" **some image url goes here **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "annotate_image(\"https://how-old.net/Images/faces2/main002.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_image(\"https://how-old.net/Images/faces2/main004.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "ms_docs_meta": {
   "author": "v-royhar",
   "description": "Get information and code samples to help you quickly get started using the Face API with Python in Cognitive Services.",
   "manager": "yutkuo",
   "ms.author": "anroth",
   "ms.date": "06/21/2017",
   "ms.service": "cognitive-services",
   "ms.technology": "face",
   "ms.topic": "article",
   "services": "cognitive-services",
   "title": "Face API Python quick start | Microsoft Docs"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
